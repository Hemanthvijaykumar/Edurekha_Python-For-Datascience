{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
    "\n",
    "from sklearn.svm import LinearSVC,SVC\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the data from “college.csv” that has attributes collected about private and public colleges for a particular year. We will try to predict the private/public status of the college from other attributes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('College.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Private</th>\n",
       "      <th>Apps</th>\n",
       "      <th>Accept</th>\n",
       "      <th>Enroll</th>\n",
       "      <th>Top10perc</th>\n",
       "      <th>Top25perc</th>\n",
       "      <th>F.Undergrad</th>\n",
       "      <th>P.Undergrad</th>\n",
       "      <th>Outstate</th>\n",
       "      <th>Room.Board</th>\n",
       "      <th>Books</th>\n",
       "      <th>Personal</th>\n",
       "      <th>PhD</th>\n",
       "      <th>Terminal</th>\n",
       "      <th>S.F.Ratio</th>\n",
       "      <th>perc.alumni</th>\n",
       "      <th>Expend</th>\n",
       "      <th>Grad.Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yes</td>\n",
       "      <td>1660</td>\n",
       "      <td>1232</td>\n",
       "      <td>721</td>\n",
       "      <td>23</td>\n",
       "      <td>52</td>\n",
       "      <td>2885</td>\n",
       "      <td>537</td>\n",
       "      <td>7440</td>\n",
       "      <td>3300</td>\n",
       "      <td>450</td>\n",
       "      <td>2200</td>\n",
       "      <td>70</td>\n",
       "      <td>78</td>\n",
       "      <td>18.1</td>\n",
       "      <td>12</td>\n",
       "      <td>7041</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yes</td>\n",
       "      <td>2186</td>\n",
       "      <td>1924</td>\n",
       "      <td>512</td>\n",
       "      <td>16</td>\n",
       "      <td>29</td>\n",
       "      <td>2683</td>\n",
       "      <td>1227</td>\n",
       "      <td>12280</td>\n",
       "      <td>6450</td>\n",
       "      <td>750</td>\n",
       "      <td>1500</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>12.2</td>\n",
       "      <td>16</td>\n",
       "      <td>10527</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yes</td>\n",
       "      <td>1428</td>\n",
       "      <td>1097</td>\n",
       "      <td>336</td>\n",
       "      <td>22</td>\n",
       "      <td>50</td>\n",
       "      <td>1036</td>\n",
       "      <td>99</td>\n",
       "      <td>11250</td>\n",
       "      <td>3750</td>\n",
       "      <td>400</td>\n",
       "      <td>1165</td>\n",
       "      <td>53</td>\n",
       "      <td>66</td>\n",
       "      <td>12.9</td>\n",
       "      <td>30</td>\n",
       "      <td>8735</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yes</td>\n",
       "      <td>417</td>\n",
       "      <td>349</td>\n",
       "      <td>137</td>\n",
       "      <td>60</td>\n",
       "      <td>89</td>\n",
       "      <td>510</td>\n",
       "      <td>63</td>\n",
       "      <td>12960</td>\n",
       "      <td>5450</td>\n",
       "      <td>450</td>\n",
       "      <td>875</td>\n",
       "      <td>92</td>\n",
       "      <td>97</td>\n",
       "      <td>7.7</td>\n",
       "      <td>37</td>\n",
       "      <td>19016</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yes</td>\n",
       "      <td>193</td>\n",
       "      <td>146</td>\n",
       "      <td>55</td>\n",
       "      <td>16</td>\n",
       "      <td>44</td>\n",
       "      <td>249</td>\n",
       "      <td>869</td>\n",
       "      <td>7560</td>\n",
       "      <td>4120</td>\n",
       "      <td>800</td>\n",
       "      <td>1500</td>\n",
       "      <td>76</td>\n",
       "      <td>72</td>\n",
       "      <td>11.9</td>\n",
       "      <td>2</td>\n",
       "      <td>10922</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Private  Apps  Accept  Enroll  Top10perc  Top25perc  F.Undergrad  \\\n",
       "0     Yes  1660    1232     721         23         52         2885   \n",
       "1     Yes  2186    1924     512         16         29         2683   \n",
       "2     Yes  1428    1097     336         22         50         1036   \n",
       "3     Yes   417     349     137         60         89          510   \n",
       "4     Yes   193     146      55         16         44          249   \n",
       "\n",
       "   P.Undergrad  Outstate  Room.Board  Books  Personal  PhD  Terminal  \\\n",
       "0          537      7440        3300    450      2200   70        78   \n",
       "1         1227     12280        6450    750      1500   29        30   \n",
       "2           99     11250        3750    400      1165   53        66   \n",
       "3           63     12960        5450    450       875   92        97   \n",
       "4          869      7560        4120    800      1500   76        72   \n",
       "\n",
       "   S.F.Ratio  perc.alumni  Expend  Grad.Rate  \n",
       "0       18.1           12    7041         60  \n",
       "1       12.2           16   10527         56  \n",
       "2       12.9           30    8735         54  \n",
       "3        7.7           37   19016         59  \n",
       "4       11.9            2   10922         15  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 777 entries, 0 to 776\n",
      "Data columns (total 18 columns):\n",
      "Private        777 non-null object\n",
      "Apps           777 non-null int64\n",
      "Accept         777 non-null int64\n",
      "Enroll         777 non-null int64\n",
      "Top10perc      777 non-null int64\n",
      "Top25perc      777 non-null int64\n",
      "F.Undergrad    777 non-null int64\n",
      "P.Undergrad    777 non-null int64\n",
      "Outstate       777 non-null int64\n",
      "Room.Board     777 non-null int64\n",
      "Books          777 non-null int64\n",
      "Personal       777 non-null int64\n",
      "PhD            777 non-null int64\n",
      "Terminal       777 non-null int64\n",
      "S.F.Ratio      777 non-null float64\n",
      "perc.alumni    777 non-null int64\n",
      "Expend         777 non-null int64\n",
      "Grad.Rate      777 non-null int64\n",
      "dtypes: float64(1), int64(16), object(1)\n",
      "memory usage: 109.3+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(777, 18)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Apps</th>\n",
       "      <td>777.0</td>\n",
       "      <td>3001.638353</td>\n",
       "      <td>3870.201484</td>\n",
       "      <td>81.0</td>\n",
       "      <td>776.0</td>\n",
       "      <td>1558.0</td>\n",
       "      <td>3624.0</td>\n",
       "      <td>48094.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accept</th>\n",
       "      <td>777.0</td>\n",
       "      <td>2018.804376</td>\n",
       "      <td>2451.113971</td>\n",
       "      <td>72.0</td>\n",
       "      <td>604.0</td>\n",
       "      <td>1110.0</td>\n",
       "      <td>2424.0</td>\n",
       "      <td>26330.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Enroll</th>\n",
       "      <td>777.0</td>\n",
       "      <td>779.972973</td>\n",
       "      <td>929.176190</td>\n",
       "      <td>35.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>434.0</td>\n",
       "      <td>902.0</td>\n",
       "      <td>6392.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Top10perc</th>\n",
       "      <td>777.0</td>\n",
       "      <td>27.558559</td>\n",
       "      <td>17.640364</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Top25perc</th>\n",
       "      <td>777.0</td>\n",
       "      <td>55.796654</td>\n",
       "      <td>19.804778</td>\n",
       "      <td>9.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F.Undergrad</th>\n",
       "      <td>777.0</td>\n",
       "      <td>3699.907336</td>\n",
       "      <td>4850.420531</td>\n",
       "      <td>139.0</td>\n",
       "      <td>992.0</td>\n",
       "      <td>1707.0</td>\n",
       "      <td>4005.0</td>\n",
       "      <td>31643.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P.Undergrad</th>\n",
       "      <td>777.0</td>\n",
       "      <td>855.298584</td>\n",
       "      <td>1522.431887</td>\n",
       "      <td>1.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>967.0</td>\n",
       "      <td>21836.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Outstate</th>\n",
       "      <td>777.0</td>\n",
       "      <td>10440.669241</td>\n",
       "      <td>4023.016484</td>\n",
       "      <td>2340.0</td>\n",
       "      <td>7320.0</td>\n",
       "      <td>9990.0</td>\n",
       "      <td>12925.0</td>\n",
       "      <td>21700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Room.Board</th>\n",
       "      <td>777.0</td>\n",
       "      <td>4357.526384</td>\n",
       "      <td>1096.696416</td>\n",
       "      <td>1780.0</td>\n",
       "      <td>3597.0</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>5050.0</td>\n",
       "      <td>8124.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Books</th>\n",
       "      <td>777.0</td>\n",
       "      <td>549.380952</td>\n",
       "      <td>165.105360</td>\n",
       "      <td>96.0</td>\n",
       "      <td>470.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>2340.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Personal</th>\n",
       "      <td>777.0</td>\n",
       "      <td>1340.642214</td>\n",
       "      <td>677.071454</td>\n",
       "      <td>250.0</td>\n",
       "      <td>850.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>6800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhD</th>\n",
       "      <td>777.0</td>\n",
       "      <td>72.660232</td>\n",
       "      <td>16.328155</td>\n",
       "      <td>8.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Terminal</th>\n",
       "      <td>777.0</td>\n",
       "      <td>79.702703</td>\n",
       "      <td>14.722359</td>\n",
       "      <td>24.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S.F.Ratio</th>\n",
       "      <td>777.0</td>\n",
       "      <td>14.089704</td>\n",
       "      <td>3.958349</td>\n",
       "      <td>2.5</td>\n",
       "      <td>11.5</td>\n",
       "      <td>13.6</td>\n",
       "      <td>16.5</td>\n",
       "      <td>39.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perc.alumni</th>\n",
       "      <td>777.0</td>\n",
       "      <td>22.743887</td>\n",
       "      <td>12.391801</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Expend</th>\n",
       "      <td>777.0</td>\n",
       "      <td>9660.171171</td>\n",
       "      <td>5221.768440</td>\n",
       "      <td>3186.0</td>\n",
       "      <td>6751.0</td>\n",
       "      <td>8377.0</td>\n",
       "      <td>10830.0</td>\n",
       "      <td>56233.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Grad.Rate</th>\n",
       "      <td>777.0</td>\n",
       "      <td>65.463320</td>\n",
       "      <td>17.177710</td>\n",
       "      <td>10.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>118.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count          mean          std     min     25%     50%  \\\n",
       "Apps         777.0   3001.638353  3870.201484    81.0   776.0  1558.0   \n",
       "Accept       777.0   2018.804376  2451.113971    72.0   604.0  1110.0   \n",
       "Enroll       777.0    779.972973   929.176190    35.0   242.0   434.0   \n",
       "Top10perc    777.0     27.558559    17.640364     1.0    15.0    23.0   \n",
       "Top25perc    777.0     55.796654    19.804778     9.0    41.0    54.0   \n",
       "F.Undergrad  777.0   3699.907336  4850.420531   139.0   992.0  1707.0   \n",
       "P.Undergrad  777.0    855.298584  1522.431887     1.0    95.0   353.0   \n",
       "Outstate     777.0  10440.669241  4023.016484  2340.0  7320.0  9990.0   \n",
       "Room.Board   777.0   4357.526384  1096.696416  1780.0  3597.0  4200.0   \n",
       "Books        777.0    549.380952   165.105360    96.0   470.0   500.0   \n",
       "Personal     777.0   1340.642214   677.071454   250.0   850.0  1200.0   \n",
       "PhD          777.0     72.660232    16.328155     8.0    62.0    75.0   \n",
       "Terminal     777.0     79.702703    14.722359    24.0    71.0    82.0   \n",
       "S.F.Ratio    777.0     14.089704     3.958349     2.5    11.5    13.6   \n",
       "perc.alumni  777.0     22.743887    12.391801     0.0    13.0    21.0   \n",
       "Expend       777.0   9660.171171  5221.768440  3186.0  6751.0  8377.0   \n",
       "Grad.Rate    777.0     65.463320    17.177710    10.0    53.0    65.0   \n",
       "\n",
       "                 75%      max  \n",
       "Apps          3624.0  48094.0  \n",
       "Accept        2424.0  26330.0  \n",
       "Enroll         902.0   6392.0  \n",
       "Top10perc       35.0     96.0  \n",
       "Top25perc       69.0    100.0  \n",
       "F.Undergrad   4005.0  31643.0  \n",
       "P.Undergrad    967.0  21836.0  \n",
       "Outstate     12925.0  21700.0  \n",
       "Room.Board    5050.0   8124.0  \n",
       "Books          600.0   2340.0  \n",
       "Personal      1700.0   6800.0  \n",
       "PhD             85.0    103.0  \n",
       "Terminal        92.0    100.0  \n",
       "S.F.Ratio       16.5     39.8  \n",
       "perc.alumni     31.0     64.0  \n",
       "Expend       10830.0  56233.0  \n",
       "Grad.Rate       78.0    118.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Use LabelEncoder to encode the target variable in to numerical form and split the data such that 20% of the data is set aside for testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    565\n",
       "0    212\n",
       "Name: Private, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "data['Private'] = encoder.fit_transform(data['Private'])\n",
    "data['Private'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Fit a linear svm from scikit learn and observe the accuracy. [Hint: Use Linear SVC] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(621, 17)\n",
      "(156, 17)\n",
      "(621,)\n",
      "(156,)\n"
     ]
    }
   ],
   "source": [
    "x = data.drop(['Private'],axis=1)\n",
    "y = data['Private']\n",
    "\n",
    "x_train, x_test , y_train, y_test = train_test_split(x,y,train_size=0.8)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8974358974358975\n",
      "classification report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.64      0.76        39\n",
      "           1       0.89      0.98      0.93       117\n",
      "\n",
      "    accuracy                           0.90       156\n",
      "   macro avg       0.91      0.81      0.85       156\n",
      "weighted avg       0.90      0.90      0.89       156\n",
      "\n",
      "confusion_matrix: [[ 25  14]\n",
      " [  2 115]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\YZQ8BX\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "linear_svc = LinearSVC()\n",
    "\n",
    "linear_svc = linear_svc.fit(x_train,y_train)\n",
    "y_predict = linear_svc.predict(x_test)\n",
    "\n",
    "print('Accuracy:',accuracy_score(y_test,y_predict))\n",
    "print('classification report:', classification_report(y_test,y_predict))\n",
    "print('confusion_matrix:', confusion_matrix(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Preprocess the data using StandardScalar and fit the same model again and observe the change in accuracy. [Hint: Refer to scikitlearn’s preprocessing methods]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Apps', 'Accept', 'Enroll', 'Top10perc', 'Top25perc', 'F.Undergrad',\n",
       "       'P.Undergrad', 'Outstate', 'Room.Board', 'Books', 'Personal', 'PhD',\n",
       "       'Terminal', 'S.F.Ratio', 'perc.alumni', 'Expend', 'Grad.Rate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Apps</th>\n",
       "      <th>Accept</th>\n",
       "      <th>Enroll</th>\n",
       "      <th>Top10perc</th>\n",
       "      <th>Top25perc</th>\n",
       "      <th>F.Undergrad</th>\n",
       "      <th>P.Undergrad</th>\n",
       "      <th>Outstate</th>\n",
       "      <th>Room.Board</th>\n",
       "      <th>Books</th>\n",
       "      <th>Personal</th>\n",
       "      <th>PhD</th>\n",
       "      <th>Terminal</th>\n",
       "      <th>S.F.Ratio</th>\n",
       "      <th>perc.alumni</th>\n",
       "      <th>Expend</th>\n",
       "      <th>Grad.Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.346882</td>\n",
       "      <td>-0.321205</td>\n",
       "      <td>-0.063509</td>\n",
       "      <td>-0.258583</td>\n",
       "      <td>-0.191827</td>\n",
       "      <td>-0.168116</td>\n",
       "      <td>-0.209207</td>\n",
       "      <td>-0.746356</td>\n",
       "      <td>-0.964905</td>\n",
       "      <td>-0.602312</td>\n",
       "      <td>1.270045</td>\n",
       "      <td>-0.163028</td>\n",
       "      <td>-0.115729</td>\n",
       "      <td>1.013776</td>\n",
       "      <td>-0.867574</td>\n",
       "      <td>-0.501910</td>\n",
       "      <td>-0.318252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.210884</td>\n",
       "      <td>-0.038703</td>\n",
       "      <td>-0.288584</td>\n",
       "      <td>-0.655656</td>\n",
       "      <td>-1.353911</td>\n",
       "      <td>-0.209788</td>\n",
       "      <td>0.244307</td>\n",
       "      <td>0.457496</td>\n",
       "      <td>1.909208</td>\n",
       "      <td>1.215880</td>\n",
       "      <td>0.235515</td>\n",
       "      <td>-2.675646</td>\n",
       "      <td>-3.378176</td>\n",
       "      <td>-0.477704</td>\n",
       "      <td>-0.544572</td>\n",
       "      <td>0.166110</td>\n",
       "      <td>-0.551262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.406866</td>\n",
       "      <td>-0.376318</td>\n",
       "      <td>-0.478121</td>\n",
       "      <td>-0.315307</td>\n",
       "      <td>-0.292878</td>\n",
       "      <td>-0.549565</td>\n",
       "      <td>-0.497090</td>\n",
       "      <td>0.201305</td>\n",
       "      <td>-0.554317</td>\n",
       "      <td>-0.905344</td>\n",
       "      <td>-0.259582</td>\n",
       "      <td>-1.204845</td>\n",
       "      <td>-0.931341</td>\n",
       "      <td>-0.300749</td>\n",
       "      <td>0.585935</td>\n",
       "      <td>-0.177290</td>\n",
       "      <td>-0.667767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.668261</td>\n",
       "      <td>-0.681682</td>\n",
       "      <td>-0.692427</td>\n",
       "      <td>1.840231</td>\n",
       "      <td>1.677612</td>\n",
       "      <td>-0.658079</td>\n",
       "      <td>-0.520752</td>\n",
       "      <td>0.626633</td>\n",
       "      <td>0.996791</td>\n",
       "      <td>-0.602312</td>\n",
       "      <td>-0.688173</td>\n",
       "      <td>1.185206</td>\n",
       "      <td>1.175657</td>\n",
       "      <td>-1.615274</td>\n",
       "      <td>1.151188</td>\n",
       "      <td>1.792851</td>\n",
       "      <td>-0.376504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.726176</td>\n",
       "      <td>-0.764555</td>\n",
       "      <td>-0.780735</td>\n",
       "      <td>-0.655656</td>\n",
       "      <td>-0.596031</td>\n",
       "      <td>-0.711924</td>\n",
       "      <td>0.009005</td>\n",
       "      <td>-0.716508</td>\n",
       "      <td>-0.216723</td>\n",
       "      <td>1.518912</td>\n",
       "      <td>0.235515</td>\n",
       "      <td>0.204672</td>\n",
       "      <td>-0.523535</td>\n",
       "      <td>-0.553542</td>\n",
       "      <td>-1.675079</td>\n",
       "      <td>0.241803</td>\n",
       "      <td>-2.939613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Apps    Accept    Enroll  Top10perc  Top25perc  F.Undergrad  \\\n",
       "0 -0.346882 -0.321205 -0.063509  -0.258583  -0.191827    -0.168116   \n",
       "1 -0.210884 -0.038703 -0.288584  -0.655656  -1.353911    -0.209788   \n",
       "2 -0.406866 -0.376318 -0.478121  -0.315307  -0.292878    -0.549565   \n",
       "3 -0.668261 -0.681682 -0.692427   1.840231   1.677612    -0.658079   \n",
       "4 -0.726176 -0.764555 -0.780735  -0.655656  -0.596031    -0.711924   \n",
       "\n",
       "   P.Undergrad  Outstate  Room.Board     Books  Personal       PhD  Terminal  \\\n",
       "0    -0.209207 -0.746356   -0.964905 -0.602312  1.270045 -0.163028 -0.115729   \n",
       "1     0.244307  0.457496    1.909208  1.215880  0.235515 -2.675646 -3.378176   \n",
       "2    -0.497090  0.201305   -0.554317 -0.905344 -0.259582 -1.204845 -0.931341   \n",
       "3    -0.520752  0.626633    0.996791 -0.602312 -0.688173  1.185206  1.175657   \n",
       "4     0.009005 -0.716508   -0.216723  1.518912  0.235515  0.204672 -0.523535   \n",
       "\n",
       "   S.F.Ratio  perc.alumni    Expend  Grad.Rate  \n",
       "0   1.013776    -0.867574 -0.501910  -0.318252  \n",
       "1  -0.477704    -0.544572  0.166110  -0.551262  \n",
       "2  -0.300749     0.585935 -0.177290  -0.667767  \n",
       "3  -1.615274     1.151188  1.792851  -0.376504  \n",
       "4  -0.553542    -1.675079  0.241803  -2.939613  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "x_scale = scaler.fit_transform(x)\n",
    "x_scale = pd.DataFrame(x_scale,columns=['Apps', 'Accept', 'Enroll', 'Top10perc', 'Top25perc', 'F.Undergrad',\n",
    "       'P.Undergrad', 'Outstate', 'Room.Board', 'Books', 'Personal', 'PhD',\n",
    "       'Terminal', 'S.F.Ratio', 'perc.alumni', 'Expend', 'Grad.Rate'])\n",
    "x_scale.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(621, 17)\n",
      "(156, 17)\n",
      "(621,)\n",
      "(156,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test , y_train, y_test = train_test_split(x_scale,y,train_size=0.8)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9423076923076923\n",
      "classification report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.88      0.89        42\n",
      "           1       0.96      0.96      0.96       114\n",
      "\n",
      "    accuracy                           0.94       156\n",
      "   macro avg       0.93      0.92      0.93       156\n",
      "weighted avg       0.94      0.94      0.94       156\n",
      "\n",
      "confusion_matrix: [[ 37   5]\n",
      " [  4 110]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\YZQ8BX\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "linear_svc = LinearSVC()\n",
    "\n",
    "linear_svc = linear_svc.fit(x_train,y_train)\n",
    "y_predict = linear_svc.predict(x_test)\n",
    "\n",
    "print('Accuracy:',accuracy_score(y_test,y_predict))\n",
    "print('classification report:', classification_report(y_test,y_predict))\n",
    "print('confusion_matrix:', confusion_matrix(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The accuracy of the model has increased significantly from 0.89 to 0.94 after scaling the data. Thus in support vector classifier\n",
    "# scaling the attributes plays an important role"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.Use scikit learn’s gridsearch to select the best hyperparameter for a non-linear SVM,identify the model with best score and its parameters.[Hint: Refer to model_selection module of Scikit learn] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9294871794871795\n",
      "classification report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.81      0.86        42\n",
      "           1       0.93      0.97      0.95       114\n",
      "\n",
      "    accuracy                           0.93       156\n",
      "   macro avg       0.93      0.89      0.91       156\n",
      "weighted avg       0.93      0.93      0.93       156\n",
      "\n",
      "confusion_matrix: [[ 34   8]\n",
      " [  3 111]]\n"
     ]
    }
   ],
   "source": [
    "# BAse model without hyper parameter tuning:\n",
    "\n",
    "SVC_base = SVC()\n",
    "\n",
    "SVC_base = SVC_base.fit(x_train,y_train)\n",
    "y_predict = SVC_base.predict(x_test)\n",
    "\n",
    "print('Accuracy:',accuracy_score(y_test,y_predict))\n",
    "print('classification report:', classification_report(y_test,y_predict))\n",
    "print('confusion_matrix:', confusion_matrix(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 84 candidates, totalling 252 fits\n"
     ]
    }
   ],
   "source": [
    "param ={'C': [0.1, 1, 100, 1000],\n",
    "        'gamma': [0.0001, 0.001, 0.005, 0.1, 1, 3, 5],\n",
    "        'kernel':['poly', 'rbf', 'sigmoid']\n",
    "        }\n",
    "\n",
    "grid = GridSearchCV(estimator=SVC(), param_grid = param , cv=3, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "best_params = grid_result.best_params_\n",
    "pred = grid_result.predict(x_test)\n",
    "cm = confusion_matrix(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best parameters:\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
       "       0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 35,   7],\n",
       "       [  4, 110]], dtype=int64)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9294871794871795\n",
      "classification report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.83      0.86        42\n",
      "           1       0.94      0.96      0.95       114\n",
      "\n",
      "    accuracy                           0.93       156\n",
      "   macro avg       0.92      0.90      0.91       156\n",
      "weighted avg       0.93      0.93      0.93       156\n",
      "\n",
      "confusion_matrix: [[ 35   7]\n",
      " [  4 110]]\n"
     ]
    }
   ],
   "source": [
    "# Building the svc model with best hyper parameters:\n",
    "svc = SVC(C=1,gamma=0.1,kernel='rbf')\n",
    "\n",
    "svc = svc.fit(x_train,y_train)\n",
    "y_predict = svc.predict(x_test)\n",
    "\n",
    "print('Accuracy:',accuracy_score(y_test,y_predict))\n",
    "print('classification report:', classification_report(y_test,y_predict))\n",
    "print('confusion_matrix:', confusion_matrix(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hyper parameter tuning increases the accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
